---
title: "Forest Inventory: Application of Horvitz-Thompson estimators in a two-stage sample"
author: "Henry Rodman"
date: "2019-02-04"
categories: ["R"]
slug: "two-stage-horvitz-thompson"
tags: ["statistics", "sampling", "forestry", "biometrics"]
header:
  image: "headers/jefferson.jpg"
  preview: TRUE
---



<p>The application of statistical survey sampling techniques to the assessment of forest resources (aka forest inventory) has been elemental to improvements in forest management practices across the globe. Sampling methods that can efficiently yield accurate and precise estimates are preferred by forest managers because collecting forest inventory data is difficult and expensive!</p>
<p>Two-stage sampling is useful in forest inventory because it can improve efficiency by reducing the number of stands (primary sample units) that are visited and by using auxilliary information for selecting sampled stands. This official name for this type of sample design is an <em>unequal probability without replacement, two-stage sample</em>. Unequal probability sampling is well documented in statistical textbooks, but the estimators for sample variance are much more complex than those for sample designs with equal probability and/or with replacement.</p>
<p>I dug around the internet, textbooks, and through my old lecture notes from forest mensuration courses and could not find a complete demonstration of a two-stage sample where the primary sample units were selected with unequal probability. The Horvitz-Thompson estimators provide most of the solution, but they need to be extended slightly to account for the variance from the second stage (sample variance within individual stands). There is much uncertainty about the best way to compute the inclusion probabilities, so I have devised a brute force simulation approach to estimating those.</p>
<div id="objectives" class="section level2">
<h2>Objectives</h2>
<p>Let’s say that I am a forest manager that needs an estimate of the volume of standing trees in a tract of forest land. I want to obtain an accurate estimate for the lowest price possible. I am willing to pay more for a more precise estimate, but do not need an estimate that is more precise than +/- 10% at 90% confidence. In statistical terms, I would like the half-width of the 90% confidence interval to be roughly 10% of the estimate of the total volume.</p>
</div>
<div id="simulate-the-population" class="section level2">
<h2>Simulate the population</h2>
<p>The forest is composed of 100 stands of forest that vary in size, most of the stands are Douglas-fir plantations. In general, we expect that older stands have greater volume stocking than young stands. We will randomly assign an age, size in acres, coefficient of variation of volume within the stand, then assign the mean cubic feet per acre for the stand.</p>
<pre class="r"><code># simulate a population of stands
stands &lt;- tibble(id = 1:100) %&gt;%
  mutate(
    acres = runif(
      n = 100, min = 10, max = 200
    ),
    age = runif(
      n = 100, min = 10, max = 150
    ),
    cv = runif(n = 100, min = 10, max = 100)
  ) %&gt;%
  mutate(
    cuftPerAc = 3000 *
      1 / (1 + exp(-(age - 40) / 15)) +
      rnorm(n = 100, mean = 0, sd = 300),
    cuftPerAc = ifelse(cuftPerAc &lt; 0, 0, cuftPerAc),
    cuftTot = cuftPerAc * acres
  )

totalAcres &lt;- sum(stands$acres)
totalCuft &lt;- sum(stands$cuftTot)

meanCuft &lt;- totalCuft / totalAcres

truth &lt;- tibble(
  source = &quot;truth&quot;,
  totalCuft = totalCuft,
  meanCuft = meanCuft
)

stands %&gt;%
  ggplot(aes(x = age, y = cuftPerAc)) +
  geom_point() +
  ylab(bquote(&quot;volume (&quot; ~ ft^{3} ~ &quot;/ac)&quot;)) +
  labs(caption = &quot;volume over age for the forest&quot;)</code></pre>
<p><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/data-1.png" width="672" /> The true population mean stocking is 2336 cubic feet per acre, the population total is 2.326763110^{7} cubic feet!</p>
</div>
<div id="designing-a-two-stage-sample" class="section level2">
<h2>Designing a two-stage sample</h2>
<p>There are many ways to obtain an estimate of the total volume for the forest. The most expensive way would be to visit every tree in the forest, measuring several dimensions and estimating volume for every single tree. This would provide us with an accurate and precise estimate but would be time consuming and prohibitively expensive. We could also just guess the total based on what we know about the property. This would be very cheap today, but our estimate is likely to be inaccurate and will probably result in significant costs related to bad information down the road. Our best bet is to take a sample from the population. A simple random sample of 1/15 acre circular plots distributed across the property would be a fine way to sample the property, but traveling to each sample point could be very inefficient and we also want information about individual stands for planning purposes. We should do something besides a simple random sample.</p>
<p>A two-stage sample is an appealing option because we can obtain an accurate estimate of the population total while obtaining stand-level estimates that we will use for modeling forest growth and evaluating forest management options. We can also improve the precision of our estimates by sampling stands with weights that we expect to be correlated with our variable of interest (total volume).</p>
<div id="selecting-stands" class="section level3">
<h3>Selecting stands</h3>
<p>The population of stands could be sampled randomly, but since we are trying to obtain an estimate of total volume for the property, we need to make sure that we sample the stands that a) contribute the most to the total volume, and b) contribute the most variance to the population. Using the Horvitz-Thompson estimators, we can sample the stands however we want so long as we know the probability of each stand being included in the sample! This is a case of unequal probability sampling and the Horvitz-Thompson estimators will be statistically efficient if the probability of inclusion for each primary sampling unit is correlated with the variable of interest. In this case, we are going to weight our sample on age x acres since we believe the oldest stands are going to have the greatest stocking, and that the largest stands have the greatest total volume.</p>
<div id="inclusion-probability" class="section level4">
<h4>Inclusion probability</h4>
<p>Some references approximate <span class="math inline">\(\pi_{i}\)</span> using <span class="math inline">\(n * p_{i}\)</span> where <span class="math inline">\(p_{i}\)</span> is the sampling weight for the <span class="math inline">\(i\)</span>th primary sample unit. This works fine when sampling with replacement, but sampling without replacement is slightly more complicated. The probability of including the <span class="math inline">\(i\)</span>th element on the <span class="math inline">\(k\)</span>th draw depends on the elements that were drawn in all draws <span class="math inline">\(1:k\)</span>. The distinction between <span class="math inline">\(p_{i}\)</span> and <span class="math inline">\(\pi_{i}\)</span> is very important. Think of <span class="math inline">\(\pi_{i}\)</span> as the likelihood of including the <span class="math inline">\(i\)</span>th element unconditional on the other elements selected in the sample. This can be calculated by computing the proportion of all possible samples where an element is selected but that sounds very difficult. Instead we will use the power of simulation to obtain an approximation of <span class="math inline">\(\pi_{i}\)</span> for each stand.</p>
<p>For this sample we are going to weight our sample on <code>age * acres</code> since we believe the oldest stands are going to have the greatest stocking, and that the largest stands have the greatest total volume. We have decided that we are going to sample 20 stands and install either one plot per 8 acres or 30 plots per stand, whichever is fewer.</p>
<pre class="r"><code>stands$prop &lt;- (stands$age * stands$acres) /
  sum(stands$age * stands$acres)

stands %&gt;%
  ggplot(aes(x = age * acres, y = cuftTot)) +
  geom_point() +
  ylab(bquote(&quot;total volume (&quot; ~ ft^{3} ~ &quot;)&quot;))</code></pre>
<p><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/sampleWeightsPlot-1.png" width="672" /></p>
<p>We need to estimate the inclusion probabilities (<span class="math inline">\(\pi_{i}\)</span>) for all stands as well as the joint inclusion probabilities (<span class="math inline">\(\pi_{ij}\)</span>) for all pairs of stands. We can accomplish this with a simulation.</p>
<pre class="r"><code>simulate_sample &lt;- function(sims, stands, nSamp, cores) {
  simFrame &lt;- bind_rows(
    parallel::mclapply(1:sims,
      function(i, ...) {
        stands %&gt;%
          sample_n(nSamp, weight = prop)
      },
      mc.cores = cores
    ),
    .id = &quot;sim&quot;
  )
  out &lt;- list(
    simFrame = simFrame,
    sims = sims,
    nSamp = nSamp,
    ids = stands$id
  )
  return(out)
}

estimate_pi_i &lt;- function(simList) {
  simList[[&quot;simFrame&quot;]] %&gt;%
    group_by(id) %&gt;%
    summarize(pi_i_sim = n() / simList[[&quot;sims&quot;]]) %&gt;%
    left_join(stands, by = &quot;id&quot;) %&gt;%
    mutate(
      pi_i_approx = simList[[&quot;nSamp&quot;]] * prop
    ) %&gt;%
    select(id, pi_i_sim, pi_i_approx, prop)
}

estimate_joint_probs &lt;- function(simList, cores) {
  ids &lt;- unique(simList[[&quot;simFrame&quot;]]$id)
  idxs &lt;- 1:length(ids)
  # unique pairs of elements
  pairs &lt;- combn(ids, m = 2, simplify = FALSE)
  
  estimate_joint_prob &lt;- function(pair, simFrame, sims, cores) {
    simFrame %&gt;%
      filter(id %in% pair) %&gt;%
      group_by(sim) %&gt;%
      mutate(n = n()) %&gt;%
      filter(n &gt; 1) %&gt;%
      ungroup() %&gt;%
      select(sim) %&gt;%
      distinct() %&gt;%
      tally %&gt;%
      rowwise() %&gt;%
      mutate(
        id1 = pair[1], id2 = pair[2],
        row = idxs[which(ids == id1)],
        col = idxs[which(ids == id2)],
        jointProb = n / sims
      ) %&gt;%
      select(-n)
  }
  
  f &lt;- bind_rows(
    parallel::mclapply(
      pairs,
      estimate_joint_prob,
      simFrame = simList[[&quot;simFrame&quot;]],
      sims = simList[[&quot;sims&quot;]],
      mc.cores = cores
    )
  )

  frame &lt;- matrix(NA, nrow = length(ids), ncol = length(ids))
  frame[as.matrix(f[3:4])] &lt;- f$jointProb
  frame[as.matrix(f[4:3])] &lt;- f$jointProb

  output &lt;- data.frame(frame)
  row.names(output) &lt;- ids
  names(output) &lt;- ids

  return(output)
}

simList20 &lt;- simulate_sample(
  sims = 10000,
  stands = stands,
  nSamp = 20,
  cores = 2
)

sampleSim20 &lt;- estimate_pi_i(simList = simList20)

jointProbs &lt;- estimate_joint_probs(
  simList = simList20,
  cores = 2
)

sampleSim20 %&gt;%
  ggplot(aes(x = pi_i_approx, y = pi_i_sim)) +
  geom_point() +
  geom_abline() +
  xlim(0, 1.1 * max(sampleSim20$pi_i_approx)) +
  ylim(0, 1.1 * max(sampleSim20$pi_i_sim)) +
  xlab(bquote(&quot;approximate&quot; ~ pi[i])) +
  ylab(bquote(&quot;simulated&quot; ~ pi[i]))</code></pre>
<p><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/inclusionProbablities-1.png" width="672" /> As you can see, there are subtle differences between the approximate <span class="math inline">\(\pi_{i}\)</span> values and the <span class="math inline">\(\pi_{i}\)</span> values generated from 10,000 simulated samples. We will use the simulated values for the rest of the analysis.</p>
<p>By plotting <span class="math inline">\(\pi_{i}\)</span> with the true total volume we can see that large stands with high volume stocking have the highest probability of inclusion in a sample of 20 stands.</p>
<pre class="r"><code>sampleSim20 %&gt;%
  left_join(stands) %&gt;%
  ggplot(
    aes(
      x = acres,
      y = cuftPerAc,
      color = pi_i_sim)
    ) +
  geom_point() +
  ylab(bquote(&quot;volume (&quot; ~ ft^{3} ~ &quot;/ac)&quot;)) +
  scale_color_continuous(
    name = bquote(&quot;simulated&quot; ~ pi[i])
  )</code></pre>
<p><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/samplingProbabilityField-1.png" width="672" /></p>
<pre class="r"><code>sampleSim20 %&gt;%
  left_join(stands) %&gt;%
  ggplot(
    aes(
      x = pi_i_sim,
      y = cuftPerAc * acres
    )
  ) +
  geom_point() +
  ylab(bquote(&quot;total volume (&quot; ~ ft^{3} ~ &quot;)&quot;)) +
  xlab(bquote(&quot;simulated&quot; ~ pi[i]))</code></pre>
<p><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/samplingProbabilityField-2.png" width="672" /></p>
</div>
</div>
</div>
<div id="example-sample" class="section level2">
<h2>Example sample</h2>
<p>Now we are going to step through a sample of the population.</p>
<pre class="r"><code>acresPerPlot &lt;- 6

sampStands &lt;- stands %&gt;%
  sample_n(size = 20, weight = prop) %&gt;%
  group_by(id) %&gt;%
  mutate(
    nPlots = max(
      2,
      min(ceiling(acres / acresPerPlot), 30)
    )
  ) %&gt;%
  left_join(
    sampleSim20 %&gt;%
      select(id, pi_i_sim),
    by = &quot;id&quot;
  ) %&gt;%
  ungroup()

stands %&gt;%
  mutate(
    sampled = case_when(
      id %in% sampStands$id ~ &quot;yes&quot;,
      ! id %in% sampStands$id ~ &quot;no&quot;
    )
  ) %&gt;%
  ggplot(
    aes(x = acres, y = cuftPerAc, color = sampled)
  ) +
  geom_point() +
  ylab(bquote(&quot;volume (&quot; ~ ft^{3} ~ &quot;/ac)&quot;))</code></pre>
<p><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/sampleStands-1.png" width="672" /></p>
<div id="measure-plots" class="section level3">
<h3>Measure plots</h3>
<p>In each sample stand we are installing a systematic random sample of 1/15 acre circular plots. On each plot we are estimating the cubic foot volume of the living trees. This is the second stage of our two-stage sample. We are simulating plots using a normal distribution based on the true mean and coefficient of variation of each stand.</p>
<pre class="r"><code>plotTab &lt;- sampStands %&gt;%
  rowwise() %&gt;%
  mutate(
    cuftObs = list(
      rnorm(
        n = nPlots,
        mean = cuftPerAc,
        sd = (cv / 100) * cuftPerAc
      )
    )
  ) %&gt;%
  select(id, cuftObs) %&gt;%
  unnest() %&gt;%
  ungroup()</code></pre>
</div>
</div>
<div id="analysis" class="section level2">
<h2>Analysis</h2>
<p>Once we are done cruising it’s time to crunch the numbers!</p>
<div id="equations" class="section level4">
<h4>Equations</h4>
<p>The Horvitz-Thompson estimator for the population total is: <span class="math display">\[
\hat{t}_{HT} = \sum_{i \in S} \displaystyle \frac{\hat{t}_{i}}{\pi_{i}}
\]</span> where <span class="math inline">\(S\)</span> is the sample of primary sample units from population sized <span class="math inline">\(N\)</span></p>
<p>The Sen-Yates-Grundy estimator for variance of the population total is:</p>
<p><span class="math display">\[
\hat{V}(\hat{t}_{HT}) = \sum_{i \in S} \sum_{\substack{k \in S \\ k &lt; i}}
\displaystyle \frac{\pi_{ik} - \pi_{i}\pi_{k}}{\pi_{ik}} \left(\frac{\hat{t}_{i}}{\pi_{i}} - \frac{\hat{t}_{k}}{\pi_{k}}\right)^{2}+
\sum_{i \in S} \displaystyle \frac{\hat{V}(\hat{t_{i}})}{\pi_{i}}
\]</span></p>
<p>where <span class="math inline">\(\pi_{ik}\)</span> is the joint inclusion probability for primary sampling units <span class="math inline">\(i\)</span> and <span class="math inline">\(k\)</span> and <span class="math inline">\(\hat{V}(\hat{t_{i}})\)</span> is the variance of the estimate for the <span class="math inline">\(i\)</span>th sample unit.</p>
<p>The Sen-Yates-Grundy formulation of the variance calculation requires each observation to be compared to the rest of the observations in the sample. There may be a more elegant way to code that part, but for now this is what I have come up with:</p>
<pre class="r"><code># Sen-Yates-Grundy formulation
var_syg &lt;- function(row, data, y, pi_i, p,
                    jointProbs = NULL) {
  data$idx &lt;- 1:nrow(data)
  a &lt;- data[row, ]
  b &lt;- data[data$idx &gt; row, ]
  n &lt;- nrow(data)
  if(row == max(data$idx)) {
    return(0)
  }
  message(
    paste0(
      &quot;row &quot;, row
    )
  )
  x &lt;- list()
  for (l in 1:nrow(b)) {
    c &lt;- b[l, ]
    r &lt;- as.character(a[[&quot;id&quot;]])
    col &lt;- as.character(c[[&quot;id&quot;]])
    jp &lt;- jointProbs[row.names(jointProbs) == r, col]

    x[[l]] &lt;- ((a[[pi_i]] * c[[pi_i]] - jp) / jp) *
      (a[[y]] / a[[pi_i]] - c[[y]] / c[[pi_i]])^2
  }

  sum(unlist(x))
}</code></pre>
</div>
<div id="stand-level-estimates" class="section level3">
<h3>Stand-level estimates</h3>
<p>We can start by summarizing the stand-level estimates. For each stand we will estimate the total volume using the mean volume per acre from the sample and the total acres of each stand. We will also compute the sample variance and estimate the total variance for each stand.</p>
<pre class="r"><code>standDat &lt;- plotTab %&gt;%
  left_join(
    sampStands %&gt;% select(id, acres, cuftPerAc, nPlots, pi_i = pi_i_sim),
    by = &quot;id&quot;
  ) %&gt;%
  group_by(id) %&gt;%
  summarize(
    tHat = mean(cuftObs * acres),
    varTHat = var(cuftObs * acres) / n(),
    nPlots = n()
  )

standDat %&gt;%
  left_join(stands) %&gt;%
  mutate(se = sqrt(varTHat)) %&gt;%
  ggplot(aes(x = cuftTot, y = tHat)) +
  geom_point() +
  geom_errorbar(aes(ymin = tHat - 1.7 * se, ymax = tHat + 1.7 * se)) +
  geom_abline() +
  xlab(bquote(&quot;true total volume (&quot; ~ ft^{3} ~ &quot;)&quot;))</code></pre>
<p><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/standStats-1.png" width="672" /></p>
</div>
<div id="population-level-estimate" class="section level3">
<h3>Population-level estimate</h3>
<p>We can now combine the estimates from the primary sampling units to obtain an estimate of the population. To do this we will use the inclusion and selection probabilities to weight each sampled stand’s contribution to the population total.</p>
<p>Using the equations listed above we will compute estimates of the population total and sampling variance of that estimate, then convert those into estimates of cubic foot volume on a per-acre basis.</p>
<pre class="r"><code>sampleSummary &lt;- standDat %&gt;%
  left_join(
    sampStands %&gt;%
      select(id, pi_i = pi_i_sim, prop),
    by = &quot;id&quot;
  ) %&gt;%
  ungroup() %&gt;%
  mutate(
    var_I_syg = unlist(
      parallel::mclapply(
        1:nrow(.),
        var_syg,
        data = .,
        y = &quot;tHat&quot;,
        pi_i = &quot;pi_i&quot;,
        p = &quot;prop&quot;,
        jointProbs = jointProbs,
        mc.cores = 12
      )
    )
  ) %&gt;%
  ungroup() %&gt;%
  summarize(
    totalCuft = sum(tHat / pi_i),
    fpcI = 1,
    fpcII = 1,
    varI = sum(var_I_syg),
    varII = sum(varTHat / pi_i),
    varTot = fpcI * varI + fpcII * varII,
    nObs = n()
  ) %&gt;%
  mutate(
    seTot = sqrt(varTot),
    ci90Tot = qt(
      1 - 0.1 / 2,
      df = nObs - 1
      ) * seTot,
    meanCuft = totalCuft / totalAcres,
    seMeanCuft = seTot / totalAcres,
    ci90MeanCuft = ci90Tot / totalAcres,
    source = &quot;estimate&quot;
  ) %&gt;%
  select(
    source, totalCuft, seTot, ci90Tot,
    meanCuft, seMeanCuft, ci90MeanCuft,
    nObs
  )

results &lt;- bind_rows(sampleSummary, truth)</code></pre>
<div id="results" class="section level4">
<h4>Results</h4>
<p>Since we know the true population mean, we are able to compare the estimate from our sample of 20 stands to the truth!</p>
<pre class="r"><code>results %&gt;%
  ggplot(aes(x = source, y = meanCuft)) +
  geom_point() +
  geom_errorbar(
    aes(
      ymax = meanCuft + ci90MeanCuft,
      ymin = meanCuft - ci90MeanCuft
    )
  ) +
  ylim(0, max((results$meanCuft + results$ci90MeanCuft)) * 1.5) +
  ylab(bquote(&quot;volume (&quot; ~ ft^{3} ~ &quot;/ac)&quot;))</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_errorbar).</code></pre>
<p><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/sampleEstimates-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="simulate-many-samples" class="section level2">
<h2>Simulate many samples</h2>
<p>Though we may be stuck with it in real life, the result of a single sample is not very helpful for evaluating the performance of a sample design. To do that we will simulate many samples and evaluate the performance of various sampling intensities by assessing trends in precision and bias.</p>
<p>We are simulating 100 samples for six sample intensities: 10, 20, and 30 stands out of the 100 in the population. Stands will be selected using the same probabilities as the example we walked through earlier.</p>
<p>The plot of simulated sample means with 90% confidence intervals and the true population mean (green line) shows that each sample intensity yields accurate estimates and the precision of estimates increases substantially as we sample more stands. <img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/simulationPlot1-1.png" width="672" /></p>
<p>We expect ~90% of samples to yield a confidence interval that contains the true mean, this simulation gives the expected result. The results indicate that the half-width of the 90% confidence interval is about 10% of the mean when we sample 20 stands out of 100.</p>
<table style="width:75%;">
<caption>summary of unequal probability sampling simulation</caption>
<colgroup>
<col width="16%" />
<col width="13%" />
<col width="15%" />
<col width="12%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">source</th>
<th align="center"># sampled stands</th>
<th align="center">average sample cu. ft. per/ac</th>
<th align="center">90% CI</th>
<th align="center">proportion of CIs containing true mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">estimate</td>
<td align="center">10</td>
<td align="center">2324</td>
<td align="center">373</td>
<td align="center">0.94</td>
</tr>
<tr class="even">
<td align="center">estimate</td>
<td align="center">20</td>
<td align="center">2349</td>
<td align="center">230</td>
<td align="center">0.91</td>
</tr>
<tr class="odd">
<td align="center">estimate</td>
<td align="center">30</td>
<td align="center">2350</td>
<td align="center">167</td>
<td align="center">0.93</td>
</tr>
<tr class="even">
<td align="center"><strong>truth</strong></td>
<td align="center"><strong>-</strong></td>
<td align="center"><strong>2336</strong></td>
<td align="center"><strong>-</strong></td>
<td align="center"><strong>-</strong></td>
</tr>
</tbody>
</table>
<p>Next, we are going to see how much more efficient the unequal probability sample is than a simple random sample for the first stage of sampling.</p>
</div>
<div id="simple-random-sample" class="section level2">
<h2>Simple random sample</h2>
<p>To run the same simulation using a simple random sample we just need to make the sample weights equal for all stands. We can use the same Horvitz-Thompson estimators since the only things we have changed are the inclusion probabilities.</p>
</div>
<div id="section" class="section level2">
<h2><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/simStatsSRS-1.png" width="672" /></h2>
<p>source # average 90% CI proportion sampled sample of CIs<br />
stands cu. ft. containing per/ac true<br />
mean<br />
———– ——— ———- ——– ———— estimate 10 2372 974 0.88</p>
<p>estimate 20 2384 616 0.96</p>
<p>estimate 30 2276 439 0.92</p>
</div>
<div id="truth---2336----" class="section level2">
<h2><strong>truth</strong> <strong>-</strong> <strong>2336</strong> <strong>-</strong> <strong>-</strong></h2>
<p>Table: summary of equal probability sampling simulation</p>
<p>The simple random sampling yields mean estimates that are much less stable than the unequal probability sample, which is the expected result. The correspondingly wide confidence intervals reflect the reduced precision of the simple random sample.</p>
<p>We can see that the unequal probability sample yields much more stable estimates with higher precision. This demonstrates how we can save lots of time and energy with a bit of extra work during the sample design phase of a resource assessment project.</p>
<p><img src="/post/horvitz-thompson/2019-02-04-horvitz_thompson_files/figure-html/simComp-1.png" width="672" /></p>
</div>
