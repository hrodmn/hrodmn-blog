---
title: "Forest Inventory: Application of Horvitz-Thompson estimators in a two stage sample"
author: "Henry Rodman"
date: "2019-02-04"
categories: ["R"]
tags: ["statistics", "sampling", "forestry", "biometrics"]

output:
  md_document:
    variant: markdown_github
    fig_width: 7
    preserve_yaml: true
---



<p>Though you may not notice it, forest management is a part of your life. The air we breath, water we drink, and our homes are all in some way composed of forest resources. To secure an adequate and sustainable supply of these resources, we manage forests. Humans have been managing forests with varying degrees of success throughout our entire history and the science of forestry has been developed to help us manage forests better than those who came before us. The application of statistical survey sampling techniques to the assessment of forest resources (aka forest inventory) has been elemental to improvements in forest management practices across the globe.</p>
<p>In any context, bad management decisions are often a product of bad information or poorly calibrated expectations for the future. The same is true in forestry and is the reason why forest inventory is so important. Efficient and unbiased sampling techniques have long been a focus in statistics, and forest managers use these methods every day to obtain the information required to make intelligent management decisions. This post is meant to outline the application of two-stage sampling to forest inventory.</p>
<div id="objectives" class="section level2">
<h2>Objectives</h2>
<p>Letâ€™s say that I am a forest manager that needs an estimate of the volume of standing trees in a tract of forest land. I want to obtain an accurate estimate for the lowest price possible. I am willing to pay more for a more precise estimate, but do not need an estimate that is more precise than +/- 10% at 90% confidence. In statistical terms, I would like the half-width of the 90% confidence interval to be roughly 10% of the estimate of the total volume.</p>
</div>
<div id="simulate-the-population" class="section level2">
<h2>Simulate the population</h2>
<p>The forest is composed of 100 stands of forest that vary in size, most of the stands are Douglas-fir plantations. In general, we expect that older stands have greater volume stocking than young stands. We will randomly assign an age, size in acres, coefficient of variation of volume within the stand, then assign the mean cubic feet per acre for the stand.</p>
<pre class="r"><code># simulate a population of stands
stands &lt;- tibble(id = 1:100) %&gt;%
  mutate(
    acres = runif(
      n = 100, min = 1, max = 400
    ),
    age = runif(
      n = 100, min = 10, max = 150
    ),
    cv = runif(n = 100, min = 10, max = 100)
  ) %&gt;%
  mutate(
    cuftPerAc = 3000 *
      1 / (1 + exp(-(age - 40) / 15)) +
      rnorm(n = 100, mean = 0, sd = 200),
    cuftPerAc = ifelse(cuftPerAc &lt; 0, 0, cuftPerAc),
    cuftTot = cuftPerAc * acres
  )

totalAcres &lt;- sum(stands$acres)
totalCuft &lt;- sum(stands$cuftTot)

meanCuft &lt;- totalCuft / totalAcres

truth &lt;- tibble(
  source = &quot;truth&quot;,
  totalCuft = totalCuft,
  meanCuft = meanCuft
)

stands %&gt;%
  ggplot(aes(x = age, y = cuftPerAc)) +
  geom_point() +
  ylab(bquote(&quot;volume (&quot; ~ ft^{3} ~ &quot;/ac)&quot;)) +
  labs(caption = &quot;volume over age for the forest&quot;)</code></pre>
<p><img src="/post/2019-02-04-horvitz_thompson_files/figure-html/data-1.png" width="672" /> The true population mean stocking is 2299 cubic feet per acre, the population total is 4.60468410^{7} cubic feet!</p>
</div>
<div id="designing-a-sample" class="section level2">
<h2>Designing a sample</h2>
<p>There are many ways to obtain an estimate of the total volume for the forest. The most expensive way would be to visit every tree in the forest, measuring several dimensions and estimating volume for every single tree. This would provide us with an accurate and precise estimate but would be time consuming and prohibitively expensive. We could also just guess the total based on what we know about the property. This would be very cheap today, but our estimate is likely to be inaccurate and will probably result in significant costs related to bad information down the road. Our best bet is to take a sample from the population. A simple random sample of 1/15 acre circular plots distributed across the property would be a fine way to sample the property, but we also want information about individual stands for planning purposes so we should do something else.</p>
<p>A double sample is an appealing option because we can obtain an accurate estimate of the population total while obtaining stand-level estimates that we will use for modeling forest growth and evaluating forest management options. We can also be more efficient in our sampling efforts by controlling the total number of stands that we must visit.</p>
<div id="selecting-stands" class="section level3">
<h3>Selecting stands</h3>
<p>The population of stands could be sampled randomly, but since we are trying to obtain an estimate of total volume for the property, we need to make sure that we sample the stands that a) contribute the most to the total volume, and b) contribute the most variance to the population. Using the Horvitz-Thompson estimators, we can sample the stands however we want so long as we know the probability of each stand being included in the sample! This is a case of <em>unequal probability sampling</em> and the Horvitz-Thompson estimators will be statistically efficient if the probability of inclusion for each primary sampling unit is correlated with the variable of interest. In this case, we are going to weight our sample on age x acres since we believe the oldest stands are going to have the greatest stocking, and that the largest stands have the greatest total volume.</p>
<div id="inclusion-probability" class="section level4">
<h4>Inclusion probability</h4>
<p>Some texts will approximate <span class="math inline">\(\pi_{i}\)</span> like this:</p>
<p><span class="math display">\[
\pi_{i} = n * p_{i}
\]</span></p>
<p>where <span class="math inline">\(p_{i}\)</span> is the sampling weight for the <span class="math inline">\(i\)</span>th primary sample unit. This works fine when sampling with replacement, but sampling without replacement is slightly more complicated. The probability of including the <span class="math inline">\(i\)</span>th element on the <span class="math inline">\(k\)</span>th draw depends on the elements that were drawn in all draws <span class="math inline">\(1:k\)</span>. The distinction between <span class="math inline">\(p_{i}\)</span> and <span class="math inline">\(\pi_{i}\)</span> is very important. Think of <span class="math inline">\(\pi_{i}\)</span> as the likelihood of including the <span class="math inline">\(i\)</span>th element unconditional on the other elements selected in the sample. This can be calculated by computing the proportion of all possible samples where an element is selected but that sounds very difficult. Instead we will use the power of simulation to obtain an approximation of <span class="math inline">\(\pi_{i}\)</span> for each stand.</p>
<p>For this sample we are going to weight our sample on <code>age * acres</code> since we believe the oldest stands are going to have the greatest stocking, and that the largest stands have the greatest total volume. We have decided that we are going to sample 20 stands and install either one plot per 8 acres or 30 plots per stand, whichever is fewer.</p>
<pre class="r"><code>stands$prop &lt;- (stands$cuftPerAc * stands$acres) /
  sum(stands$cuftPerAc * stands$acres)

simulate_sample &lt;- function(sims, stands, nSamp) {
  bind_rows(
    lapply(1:sims,
      function(i, ...) {
        stands %&gt;%
          sample_n(nSamp, weight = prop) %&gt;%
          mutate(try = i)
      }
    )) %&gt;%
    group_by(id) %&gt;%
    summarize(pi_i_sim = n() / sims) %&gt;%
    left_join(stands, by = &quot;id&quot;) %&gt;%
    mutate(
      pi_i_approx = nSamp * prop
    ) %&gt;%
    select(id, pi_i_sim, pi_i_approx, prop)
}

sampleSim20 &lt;- simulate_sample(
  sims = 10000,
  stands = stands,
  nSamp = 20
)

sampleSim20 %&gt;%
  ggplot(aes(x = pi_i_approx, y = pi_i_sim)) +
  geom_point() +
  geom_abline() +
  xlim(0, 1.1 * max(sampleSim20$pi_i_approx)) +
  ylim(0, 1.1 * max(sampleSim20$pi_i_sim)) +
  xlab(bquote(&quot;approximate&quot; ~ pi[i])) +
  ylab(bquote(&quot;simulated&quot; ~ pi[i]))</code></pre>
<p><img src="/post/2019-02-04-horvitz_thompson_files/figure-html/sampleSimulation-1.png" width="672" /> As you can see, there are subtle differences between the approximate <span class="math inline">\(\pi_{i}\)</span> values and the <span class="math inline">\(\pi_{i}\)</span> values generated from 10,000 simulated samples. We will use the simulated values for the rest of the analysis.</p>
<p>By plotting <span class="math inline">\(\pi_{i}\)</span> in volume and stand acreage space we can see that large stands with high volume stocking have the highest probability of inclusion in a sample of 20 stands.</p>
<pre class="r"><code>sampleSim20 %&gt;%
  left_join(stands) %&gt;%
  ggplot(
    aes(
      x = acres,
      y = cuftPerAc,
      color = pi_i_sim)
    ) +
  geom_point() +
  ylab(bquote(&quot;volume (&quot; ~ ft^{3} ~ &quot;/ac)&quot;)) +
  scale_color_continuous(
    name = bquote(&quot;simulated&quot; ~ pi[i])
  )</code></pre>
<pre><code>## Joining, by = c(&quot;id&quot;, &quot;prop&quot;)</code></pre>
<p><img src="/post/2019-02-04-horvitz_thompson_files/figure-html/samplingProbabilityField-1.png" width="672" /></p>
<p>Now we are going to step through a sample of the population.</p>
<pre class="r"><code>acresPerPlot &lt;- 8

sampStands &lt;- stands %&gt;%
  sample_n(size = 20, weight = prop) %&gt;%
  group_by(id) %&gt;%
  mutate(
    nPlots = max(
      2,
      min(ceiling(acres / acresPerPlot), 30)
    )
  ) %&gt;%
  left_join(
    sampleSim20 %&gt;%
      select(id, pi_i = pi_i_sim),
    by = &quot;id&quot;
  )
  
stands %&gt;%
  mutate(
    sampled = case_when(
      id %in% sampStands$id ~ &quot;yes&quot;,
      ! id %in% sampStands$id ~ &quot;no&quot;
    )
  ) %&gt;%
  ggplot(
    aes(x = acres, y = cuftPerAc, color = sampled)
  ) +
  geom_point()</code></pre>
<p><img src="/post/2019-02-04-horvitz_thompson_files/figure-html/sampleStands-1.png" width="672" /></p>
</div>
</div>
<div id="measure-plots" class="section level3">
<h3>Measure plots</h3>
<p>In each sample stand we are installing a systematic random sample of 1/15 acre circular plots. On each plot we are estimating the cubic foot volume of the living trees. This is the second stage of our two-stage sample. We are simulating plots using a truncated normal distribution based on the true mean and coefficient of variation of each stand. We are using a truncated normal distribution with a lower limit of 0 since it is not possible to observe negative volume!</p>
<pre class="r"><code>plotTab &lt;- sampStands %&gt;%
  rowwise() %&gt;%
  mutate(
    cuftObs = list(
      rnorm(# biological maximum
        n = nPlots,
        mean = cuftPerAc,
        sd = (cv / 100) * cuftPerAc
      )
    )
  ) %&gt;%
  select(id, cuftObs) %&gt;%
  unnest() %&gt;%
  ungroup()</code></pre>
</div>
</div>
<div id="analysis" class="section level2">
<h2>Analysis</h2>
<p>Once we are done cruising itâ€™s time to crunch the numbers!</p>
<div id="stand-level-estimates" class="section level3">
<h3>Stand-level estimates</h3>
<p>We can start by summarizing the stand-level estimates. For each stand we will estimate the total volume using the mean volume per acre from the sample and the total acres of each stand. We will also compute the sample variance and estimate the total variance for each stand.</p>
<pre class="r"><code>standDat &lt;- plotTab %&gt;%
  left_join(
    sampStands %&gt;% select(id, acres, cuftPerAc),
    by = &quot;id&quot;
  ) %&gt;%
  group_by(id, acres) %&gt;%
  summarize(
    meanObs = mean(cuftObs),
    tHat = mean(cuftObs * acres),
    varTHat = var(cuftObs * acres) / n(),
    sdObs = sd(cuftObs),
    nPlots = n()
  )</code></pre>
</div>
<div id="population-level-estimate" class="section level3">
<h3>Population-level estimate</h3>
<p>We can now combine the estimates from the primary sampling units to obtain an estimate of the population. To do this we will use the inclusion and selection probabilities to weight each sampled standâ€™s contribution to the population total.</p>
<div id="equations" class="section level4">
<h4>Equations</h4>
<p>The Horvitz-Thompson estimator for the population total is: <span class="math display">\[
\hat{t}_{HT} = \sum_{i \in S} \displaystyle \frac{\hat{t}_{i}}{\pi_{i}}
\]</span> where <span class="math inline">\(S\)</span> is the sample of primary sample units from population sized <span class="math inline">\(N\)</span></p>
<p>The estimator for variance of the population total is:</p>
<p><span class="math display">\[
\hat{V}(\hat{t}_{HT}) = \sum_{i \in S} (1 - \pi_{i}) \displaystyle \frac{\hat{t_{i}}^{2}}{\pi_{i}^{2}}+
\sum_{i \in S} \sum_{\substack{k \in S \\ k \neq i}} \displaystyle \frac{\pi_{ik} - \pi_{i}\pi_{k}}{\pi_{ik}}
\displaystyle \frac{\hat{t}_{i}}{\pi_{i}} \frac{\hat{t}_{k}}{\pi_{k}} +
\sum_{i \in S} \displaystyle \frac{\hat{V}(\hat{t_{i}})}{\pi_{i}}
\]</span></p>
<p>where <span class="math inline">\(\pi_{ik}\)</span> is the joint inclusion probability for primary sampling units <span class="math inline">\(i\)</span> and <span class="math inline">\(k\)</span>.</p>
<p><span class="math inline">\(\pi_{ik}\)</span> is approximated using this equation:</p>
<p><span class="math display">\[
\pi_{ik} = \pi_{i} + \pi_{k} - (1 - (1 - p_{i} - p_{k})^n)
\]</span></p>
<p>We will extend the estimate of population variance (<span class="math inline">\(\hat{V}(\hat{t}_{HT})\)</span>) to obtain a standard error and 90% confidence interval for the population.</p>
<p>There is one component of the variance calculation where each observation must be compared to the rest of the observations in the sample. There may be a more elegant way to code that part, but for now this is what I have come up with:</p>
<pre class="r"><code>sub_var &lt;- function(row, data, y, pi_i, p) {
  a &lt;- data[row, ]
  b &lt;- data[-row, ]
  n &lt;- nrow(data)

  x &lt;- list()
  for (l in 1:nrow(b)) {
    c &lt;- b[l, ]

    jp &lt;- a[[pi_i]] + c[[pi_i]] -
      (1 - (1 - a[[p]] - c[[p]])^n)

    x[[l]] &lt;- ((jp - a[[pi_i]] * c[[pi_i]]) /
      a[[pi_i]] * c[[pi_i]]) *
      a[[y]] * c[[y]] / jp
  }

  sum(unlist(x))
}</code></pre>
<p>Using the equations listed above we will compute estimates of the population total and variance of the total, then convert those into estimates of cubic foot volume on a per-acre basis.</p>
<pre class="r"><code>sampleSummary &lt;- standDat %&gt;%
  left_join(
    sampStands %&gt;%
      select(id, pi_i, prop),
    by = &quot;id&quot;
  ) %&gt;%
  ungroup() %&gt;%
  mutate(
    subVar = unlist(
      lapply(
        1:nrow(.),
        sub_var,
        data = .,
        y = &quot;tHat&quot;,
        pi_i = &quot;pi_i&quot;,
        p = &quot;prop&quot;
      )
    )
  ) %&gt;%
  ungroup() %&gt;%
  summarize(
    totalCuft = sum(tHat / pi_i),
    fpc = 1 - n() / nrow(stands),
    varTot = fpc * (
      sum(((1 - pi_i) / pi_i^2) * tHat^2) +
        sum(subVar) + sum(varTHat / pi_i)
      ),
    nObs = n()
  ) %&gt;%
  mutate(
    seTot = sqrt(varTot / nObs),
    ci90Tot = qt(
      1 - 0.1 / 2,
      df = nObs - 1
      ) * seTot,
    meanCuft = totalCuft / totalAcres,
    seMeanCuft = seTot / totalAcres,
    ci90MeanCuft = ci90Tot / totalAcres,
    source = &quot;estimate&quot;
  ) %&gt;%
  select(
    source, totalCuft, seTot, ci90Tot,
    meanCuft, seMeanCuft, ci90MeanCuft,
    nObs
  )

results &lt;- bind_rows(sampleSummary, truth)</code></pre>
</div>
<div id="results" class="section level4">
<h4>Results</h4>
<p>Since we know the true population mean, we are able to compare the estimate from our sample of 20 stands to the truth!</p>
<pre class="r"><code>results %&gt;%
  ggplot(aes(x = source, y = meanCuft)) +
  geom_point() +
  geom_errorbar(
    aes(
      ymax = meanCuft + ci90MeanCuft,
      ymin = meanCuft - ci90MeanCuft
    )
  ) +
  ylim(0, max(standDat$meanObs) * 1.5) +
  ylab(bquote(&quot;volume (&quot; ~ ft^{3} ~ &quot;/ac)&quot;))</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_errorbar).</code></pre>
<p><img src="/post/2019-02-04-horvitz_thompson_files/figure-html/sampleEstimates-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="simulate-many-samples" class="section level2">
<h2>Simulate many samples</h2>
<p>Though we may be stuck with it in real life, the result of a single sample is not very helpful for evaluating the performance of a sample design. To do that we will simulate many samples and evaluate the performance of various sampling intensities by assessing trends in precison and bias.</p>
<p>We are simulating 100 samples for six sample intensities: 10, 20, 30, 40, 50, and 60 stands out of the 100 in the population. Stands will be selected using the same probabilities as the example we walked through earlier.</p>
<pre class="r"><code>simFrame &lt;- bind_rows(
  map(
    .x = c(10, 20, 30, 40, 50, 60),
    .f = simulate_HT,
    stands = stands,
    sims = 100,
    acresPerPlot = acresPerPlot
  )
)

simStats &lt;- simFrame %&gt;%
  mutate(
    meanInCI = ifelse(
      truth$meanCuft &lt;= meanCuft + ci90MeanCuft &amp;
        truth$meanCuft &gt;= meanCuft - ci90MeanCuft,
      TRUE,
      FALSE
    )
  ) %&gt;%
  group_by(source, nObs) %&gt;%
  summarize(
    meanCuft = mean(meanCuft),
    ci90MeanCuft = mean(ci90MeanCuft),
    propMatchCI = mean(meanInCI)
  )</code></pre>
<p>The histograms of sample mean for each level of sampling intensity shows that the sample means become more stable as we increase sample size.</p>
<pre class="r"><code>ggplot(data = simFrame, aes(x = meanCuft)) +
  geom_histogram() +
  theme_bw() +
  facet_wrap(~nObs) +
  xlim(0, max(simFrame$meanCuft)) +
  geom_vline(
    xintercept = truth$meanCuft,
    color = &quot;blue&quot;
  ) +
  geom_vline(
    data = simStats,
    aes(xintercept = meanCuft),
    color = &quot;red&quot;
  )</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 12 rows containing missing values (geom_bar).</code></pre>
<p><img src="/post/2019-02-04-horvitz_thompson_files/figure-html/simulationPlot1-1.png" width="672" /></p>
<p>The plot of simulated sample means with 90% confidence intervals and the true population mean (green line) shows that each sample intensity yields accurate estimates, but the precision of estimates increases substantially as we sample more stands.</p>
<pre class="r"><code>simFrame %&gt;%
  group_by(nObs) %&gt;%
  mutate(sim = row_number()) %&gt;%
  ggplot(aes(x = meanCuft, y = sim)) +
  geom_errorbarh(
    aes(
      xmin = meanCuft - ci90MeanCuft,
      xmax = meanCuft + ci90MeanCuft
    ),
    alpha = 0.8,
    color = &quot;orange&quot;
  ) +
  geom_point(size = 1, alpha = 0.8) +
  geom_vline(
    aes(xintercept = truth$meanCuft),
    color = &quot;green&quot;
  ) +
  facet_wrap(~ nObs) +
  xlim(
    0,
    max(simFrame$meanCuft) +
      max(simFrame$ci90MeanCuft)
  )</code></pre>
<p><img src="/post/2019-02-04-horvitz_thompson_files/figure-html/simulationPlot2-1.png" width="672" /></p>
<p>Based on the criteria we set for acceptable precision (+/- 10% of mean at 90% confidence), we should be able to get by with a sample of 20 stands!</p>
<pre class="r"><code>outTable &lt;- simStats %&gt;%
  bind_rows(truth %&gt;% select(source, meanCuft)) %&gt;%
  rename(
    &quot;# sampled stands&quot; = nObs,
    &quot;average sample cu. ft. per/ac&quot; = meanCuft,
    &quot;90% CI&quot; = ci90MeanCuft,
    &quot;proportion of CIs containing true mean&quot; = propMatchCI
  )
pander::pander(
  outTable,
  missing = &quot;-&quot;,
  emphasize.strong.rows = which(outTable$source == &quot;truth&quot;)
)</code></pre>
<table style="width:75%;">
<colgroup>
<col width="16%" />
<col width="13%" />
<col width="15%" />
<col width="12%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">source</th>
<th align="center"># sampled stands</th>
<th align="center">average sample cu. ft. per/ac</th>
<th align="center">90% CI</th>
<th align="center">proportion of CIs containing true mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">estimate</td>
<td align="center">10</td>
<td align="center">2307</td>
<td align="center">391.9</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">estimate</td>
<td align="center">20</td>
<td align="center">2292</td>
<td align="center">212.3</td>
<td align="center">0.98</td>
</tr>
<tr class="odd">
<td align="center">estimate</td>
<td align="center">30</td>
<td align="center">2286</td>
<td align="center">174.8</td>
<td align="center">0.99</td>
</tr>
<tr class="even">
<td align="center">estimate</td>
<td align="center">40</td>
<td align="center">2295</td>
<td align="center">154.2</td>
<td align="center">0.99</td>
</tr>
<tr class="odd">
<td align="center">estimate</td>
<td align="center">50</td>
<td align="center">2298</td>
<td align="center">131.9</td>
<td align="center">0.99</td>
</tr>
<tr class="even">
<td align="center">estimate</td>
<td align="center">60</td>
<td align="center">2290</td>
<td align="center">107</td>
<td align="center">0.93</td>
</tr>
<tr class="odd">
<td align="center"><strong>truth</strong></td>
<td align="center"><strong>-</strong></td>
<td align="center"><strong>2299</strong></td>
<td align="center"><strong>-</strong></td>
<td align="center"><strong>-</strong></td>
</tr>
</tbody>
</table>
</div>
